<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kevin Lin</title>

    <meta name="author" content="Kevin Lin">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Kevin Lin</name>
                                    </p>
                                    <p>MS Computer Science at Stanford, advised by <a href="https://web.stanford.edu/~bohg/">Jeannette Bohg</a>; previously, EECS at UC Berkeley. I did research at <a href="https://waabi.ai/">Waabi</a>, advised by Raquel Urtasun, and at 
                                        <a href="https://bair.berkeley.edu/">Berkeley Artificial Intelligence Research </a> with members of <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel's</a> Robot Learning Lab. 
                                        I also did research with <a href="https://smlbansal.github.io/">Somil Bansal</a>.
                                    </p>

                                    <p>If you're interested in collaborating or getting into robotics, feel free to email!</p>

                                    <p style="text-align:center">
                                        <a href="mailto:kevin.lin@cs.stanford.edu">Email</a> &nbsp/&nbsp
                                        <a href="https://www.linkedin.com/in/kevin-thankyou-lin/">LinkedIn</a> &nbsp/&nbsp
                                        <a href="https://github.com/kevin-thankyou-lin">Github</a>
                                    </p>
                                </td>
                                <td style="padding:2.5%;width:40%;max-width:40%">
                                    <a><img style="width:100%;max-width:100%;border-radius:50%;" alt="profile photo" src="./images/kevinlin.png" class="hoverZoomLink rounded-circle"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Research</heading>
                                    <p>
                                        I'm interested in developing general purpose robots. 
                                    </p>
                                    <p>
                                        Previously, I have leveraged foundation models for robust and verified 
                                        long horizon planning for robot manipulation from natural language instructions.

                                        Currently, I'm developing a general purpose robotic manipulation framework so that robots can achieve three nines of reliability on tasks when provided a few demonstrations.
                                    </p>
                                    <p>
                                        In the future, I aim to develop a general purpose robotics foundation model that can be fine tuned for specific robot embodiments and settings.
                                        I plan to achieve this goal by leveraging a diverse range of data sources --- real world robot data, simulation data, human videos --- and using
                                        methods from machine learning, vision, graphics, and robotics.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>

                            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one" style="margin-top: -70px;">
                                        <div class="two" id="dualrefl_image">
                                          <video src="videos/cp-dp.mp4" width="160" autoplay loop muted></video>
                                        </div>
                                        <video src="videos/cp-dp.mp4" width="160" autoplay loop muted></video>
                                    </div>
                                    <script type="text/javascript">
                                        function dualrefl_start() {
                                          document.getElementById('dualrefl_image').style.opacity = "1";
                                        }
                        
                                        function dualrefl_stop() {
                                          document.getElementById('dualrefl_image').style.opacity = "0";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                        <papertitle>Consistency Policy: Accelerated Visuomotor Policies via Consistency Trajectory Distillation</papertitle>
                                        <br>
                                        <a href="https://www.linkedin.com/in/aaditya-prasad/">Aaditya Prasad</a>,
                                        <strong>Kevin Lin</strong>,
                                        <a href="https://alexzhou907.github.io/">Linqi Zhou</a>,
                                        <a href="https://web.stanford.edu/~bohg/">Jeannette Bohg</a>
                                        <br>
                                    <p>In submission: <a href="https://roboticsconference.org/">Robotics Science and Systems '24</a><br></p>
                                <p>
                                    We propose Consistency Policy, a faster and similarly powerful alternative to Diffusion Policy for learning visuomotor robotic manipulation policies. 
                                    By virtue of its fast inference speed, Consistency Policy can enable low latency decision making in resource-constrained robotic setups. 
                                    We compare Consistency Policy with Diffusion Policy and other related speed-up methods across 6 simulation tasks as well as one real-world task where we demonstrate inference on a laptop GPU. 
                                    For all these tasks, Consistency Policy speeds up inference by an order of magnitude compared to the fastest alternative method and maintains competitive success rates. 
                                    </p>
                                </td>
                            </tr>

                            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='dualrefl_image'>
                                            <img src='images/droid.gif' width="160"></div>
                                        <img src='images/droid.gif' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function dualrefl_start() {
                                          document.getElementById('dualrefl_image').style.opacity = "1";
                                        }
                        
                                        function dualrefl_stop() {
                                          document.getElementById('dualrefl_image').style.opacity = "0";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://imrss2022.github.io/contributions/lin.pdf">
                                        <papertitle>DROID: A Large-Scale In-The-Wild Robot Manipulation Dataset</papertitle>
                                    </a>
                                    <br>
                                    <a href="https://www.linkedin.com/in/alexander-khazatsky-b98841149/">Alexander Khazatsky*</a>,
                                    <a href="https://kpertsch.github.io/">Karl Pertsch*</a>,...,
                                    <strong>Kevin Lin</strong>, ...,
                                    <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>,
                                    <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
                                    <br>
                                    <p>In submission: <a href="https://roboticsconference.org/">Robotics Science and Systems '24</a><br></p>
                                <p>
                                    We introduce DROID, the most diverse robot manipulation dataset to date. It contains 76k demonstration trajectories or 350 hours of interaction data, 
                                    collected across 564 scenes and 84 tasks by 50 data collectors in North America, Asia, and Europe over the course of 12 months. 
                                    We demonstrate that training with DROID leads to policies with higher performance and improved generalization ability. 
                                    We open source the full dataset, policy learning code, and a detailed guide for reproducing our robot hardware setup.
                                </p>
                                </td>
                            </tr>

                            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id="dualrefl_image">
                                          <video src="videos/t2m.mp4" width="160" autoplay loop muted></video>
                                        </div>
                                        <video src="videos/t2m.mp4" width="160" autoplay loop muted></video>
                                    </div>
                                    <script type="text/javascript">
                                        function dualrefl_start() {
                                          document.getElementById('dualrefl_image').style.opacity = "1";
                                        }
                        
                                        function dualrefl_stop() {
                                          document.getElementById('dualrefl_image').style.opacity = "0";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://sites.google.com/stanford.edu/text2motion">
                                        <papertitle>Text2Motion: From Natural Language Instructions to Feasible Plans</papertitle>
                                    </a>
                                    <br>
                                    <strong>Kevin Lin</strong>,
                                    <a href="https://www.chrisagia.com">Christopher Agia</a>,
                                    <a href="https://cs.stanford.edu/~takatoki/">Toki Migimatsu</a>,
                                    <a href="https://web.stanford.edu/~pavone/">Marco Pavone</a>,
                                    <a href="https://web.stanford.edu/~bohg/ ">Jeannette Bohg</a>
                                    <br>
                                    <p><a href="https://link.springer.com/article/10.1007/s10514-023-10131-7">Autonomous Robots '23 (Special Issue: Large Language Models in Robotics)</a><br><a href="https://microsoft.github.io/robotics.pretraining.workshop.icra/">ICRA '23 Workshop on Pretraining for Robotics</a></p>
                                <p>
                                    We propose Text2Motion, a language-based planning framework enabling robots to solve sequential manipulation tasks that require long-horizon reasoning. 
                                    Given a natural language instruction, our framework constructs both a task- and motion-level plan that is verified to reach inferred symbolic goals. 
                                </p>
                                </td>
                            </tr>

                            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='dualrefl_image'>
                                            <img src='images/textured_sofa.png' width="160"></div>
                                        <img src='images/textured_sofa.png' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function dualrefl_start() {
                                          document.getElementById('dualrefl_image').style.opacity = "1";
                                        }
                        
                                        function dualrefl_stop() {
                                          document.getElementById('dualrefl_image').style.opacity = "0";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://imrss2022.github.io/contributions/lin.pdf">
                                        <papertitle>Partial-View Object View Synthesis via Filtering Inversion</papertitle>
                                    </a>
                                    <br>
                                    <a href="https://cs.stanford.edu/~sunfanyun">Fan-Yun Sun</a>,
                                    <a href="https://research.nvidia.com/person/jonathan-tremblay">Jonathan Tremblay</a>,
                                    <a href="https://www.cs.cornell.edu/~valts/">Valts Blukis</a>,
                                    <strong>Kevin Lin</strong>,
                                    <a href="https://faculty.cc.gatech.edu/~danfei/">Danfei Xu</a>,
                                    <a href="https://www.borisivanovic.com/">Boris Ivanovic</a>,
                                    <a href="http://karkus.tilda.ws/">Peter Karkus</a>,
                                    <a href="https://cecas.clemson.edu/~stb/">Stan Birchfield</a>,
                                    <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a>,
                                    <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
                                    <a href="https://yunzhuli.github.io/">Yunzhu Li</a>,
                                    <a href="https://jiajunwu.com/">Jiajun Wu</a>,
                                    <a href="https://research.nvidia.com/person/marco-pavone">Marco Pavone</a>,
                                    <a href="https://ed.stanford.edu/faculty/nhaber">Nick Haber</a>
                                    <br>
                                    <p><a href="https://3dvconf.github.io/2024/">International Conference on 3D Vision '24</a></p>
                                <p>
                                    We propose a framework that combines the strengths of generative modeling and network finetun-ing to generate photorealistic 3D renderings of real-world objects
                                    from sparse and sequential RGB inputs.
                                </p>
                                </td>
                            </tr>

                            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='dualrefl_image'>
                                            <img src='images/rfe_camera_on_camera.jpg' width="160"></div>
                                        <img src='images/rfe_camera_on_camera.jpg' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function dualrefl_start() {
                                          document.getElementById('dualrefl_image').style.opacity = "1";
                                        }
                        
                                        function dualrefl_stop() {
                                          document.getElementById('dualrefl_image').style.opacity = "0";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://imrss2022.github.io/contributions/lin.pdf">
                                        <papertitle>Active View Planning for Radiance Fields</papertitle>
                                    </a>
                                    <br>
                                    <strong>Kevin Lin</strong>,
                                    <a href="https://brentyi.com/ ">Brent Yi</a>
                                    <br>
                                    <p><a href="https://imrss2022.github.io/">RSS '22 Workshop on Implicit Representations for Robot Manipulation</a></p>
                                <p>
                                    We motivate, discuss, and present a study on the problem of view planning for radiance fields. We introduce a benchmark, <a href="https://github.com/kevin-thankyou-lin/active-3d-gym">active-3d-gym</a>,
                                    for evaluating view planning algorithms for radiance field reconstructions and propose a simple solution to the view planning problem based on <i>radiance field ensembles</i>.
                                </p>
                                </td>
                            </tr> 
                            
                            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='dualrefl_image'>
                                            <img src='images/LBWayPt-Nav-3d.jpg' width="160"></div>
                                        <img src='images/LBWayPt-Nav-3d.jpg' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function dualrefl_start() {
                                          document.getElementById('dualrefl_image').style.opacity = "1";
                                        }
                        
                                        function dualrefl_stop() {
                                          document.getElementById('dualrefl_image').style.opacity = "0";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2112.03554">
                                        <papertitle>Combining optimal control and learning for autonomous aerial navigation in novel indoor environments</papertitle>
                                    </a>
                                    <br>
                                    <strong>Kevin Lin</strong>,
                                    <a>Brian Huo</a>,
                                    <a>Megan Hu</a>
                                    <br>
                                    <p><a href="https://arxiv.org/abs/2112.03554">Arxiv '21</a></p>
                                <p>
                                    We study how aerial robots can autonomously learn to navigate safely in novel indoor environments by combining optimal control and learning techniques. We train our agent entirely in simulation and demonstrate generalization on novel indoor scenes.
                                </p>
                                </td>
                            </tr> 

                            <tr onmouseout="dualrefl_stop() " onmouseover="dualrefl_start() ">
                                <td style="padding:20px;width:25%;vertical-align:middle ">
                                    <div class="one ">
                                        <div class="two " id='dualrefl_image'>
                                            <img src='images/beliefandlevelkreasoningimg.png' width="160 "></div>
                                        <img src='images/beliefandlevelkreasoningimg.png' width="160 ">
                                    </div>
                                    <script type="text/javascript ">
                                        function dualrefl_start() {
                                        document.getElementById('dualrefl_image').style.opacity = "1 ";
                                        }
                        
                                        function dualrefl_stop() {
                                        document.getElementById('dualrefl_image').style.opacity = "0 ";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle ">
                                    <a href="https://drive.google.com/file/d/1fQJoQsX_L4x-bw-tMBO28KrypIcxSrqT/view ">
                                        <papertitle>Beliefs and Level-k Reasoning in Traffic</papertitle>
                                    </a>
                                    <br>
                                    <a href="https://eugenevinitsky.github.io/ ">E Vinitsky</a>,
                                    <a href="https://filangel.github.io/website/ ">A Filos</a>,
                                    <strong>Kevin Lin</strong>,
                                    <a href="https://www.linkedin.com/in/nickl77/ ">N Liu</a>,
                                    <a href="https://github.com/nathanlct ">N Lichtle</a>,
                                    <a href="https://people.eecs.berkeley.edu/~anca/ ">A Dragan</a>,
                                    <a href="https://bayen.berkeley.edu/alex-bayen ">A Bayen</a>,
                                    <a href="https://people.eecs.berkeley.edu/~rmcallister/ ">R McAllister</a>,
                                    <a href="https://www.jakobfoerster.com/">J Foerster</a>

                                    <br>
                                    <br>
                                    <p><a href="https://sites.google.com/view/emecom2020/home?authuser=0 ">4th NeurIPS Workshop on Emergent Communication</a></p>
                                    <p></p>
                                    <p>
                                        Occlusions present a major obstacle to guaranteeing safety in autonomous driving. Our key insight is that, sometimes, 
                                        AV can get information about occluded regions by inferring over the actions of other agents on the road. 
                                        We demonstrate that AVs can use this inferred data and level-K reasoning to avoid collisions with occluded pedestrians and drive in a pro-social manner.
                                    </p>
                                </td>
                            </tr>

                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Projects</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>

                            <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                                <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                        <div class="two" id='dualrefl_image'>
                                            <img src='images/tesroo.jpg' width="160"></div>
                                        <img src='images/tesroo.jpg' width="160">
                                    </div>
                                    <script type="text/javascript">
                                        function dualrefl_start() {
                                          document.getElementById('dualrefl_image').style.opacity = "1";
                                        }
                        
                                        function dualrefl_stop() {
                                          document.getElementById('dualrefl_image').style.opacity = "0";
                                        }
                                        dualrefl_stop()
                                    </script>
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    
                                    <papertitle><a href= "https://sites.google.com/berkeley.edu/tesroo-106a/home?authuser=0">Tesroo: A Redesigned Vacuum Robot</a></papertitle>

                                    <br>
                                    <br>
                                    <p>Won 1st place in UC Berkeley robotics course's final project</a></p>

                      <p>
                        Envisioned and built a prototype vision-only robot vacuum using Visual SLAM to compete with LiDAR based Roomba models.
                      </p>
                    </td>
                  </tr> 

                  <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='dualrefl_image'>
                                <img src='images/flow.jpg' width="160"></div>
                            <img src='images/flow.jpg' width="160">
                        </div>
                        <script type="text/javascript">
                            function dualrefl_start() {
                              document.getElementById('dualrefl_image').style.opacity = "1";
                            }
            
                            function dualrefl_stop() {
                              document.getElementById('dualrefl_image').style.opacity = "0";
                            }
                            dualrefl_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        
                        <papertitle><a href= "https://flow-project.github.io/">FLOW: A deep reinforcement learning framework for mixed autonomy traffic</a></papertitle>

                        <br>
                        <br>
                        <p>
                            Developed an open-source tool for applying ML techniques to autonomous vehicle driving policy discovery
                        </p>
                        </td>
                    </tr> 

                        </tbody>
                    </table>


                    <table width="100% " align="center " border="0 " cellspacing="0 " cellpadding="20 ">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Teaching</heading>
                                    <h4>Feel free to share your feedback <a href="https://docs.google.com/forms/d/e/1FAIpQLSfSj89DF2Yxgc_Er93d0D91z-bTjREtTA9bGsDelAfYRdIkkA/viewform ">here</a></h4>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100% " align="center " border="0 " cellpadding="20 ">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle ">
                                    <img width="75% " src="images/170pnpenguin.png " alt="cs170 ">
                                </td>
                                <td width="75% " valign="center ">
                                    <a href="https://inst.eecs.berkeley.edu/~ee126/sp21/ ">Undergraduate Student Instructor, EE 126 Spring 2021</a>
                                    <p>Probability and Random Processes</p>
                                    <a href="https://cs170.org/ ">Undergraduate Student Instructor, CS 170 Fall 2020</a>
                                    <p>Efficient Algorithms and Intractable Problems</p>
                                    <a href="http://www.eecs70.org/ ">Undergraduate Student Instructor, CS 70 Summer 2020</a>
                                    <p>Discrete Math and Probability Theory</p>
                                    <br>
                                    <br>
                                </td>
                            </tr>
                </td>
            </tr>
            </table>
</body>

</html>